{"name":"Assignment 5: Advanced Monte Carlo Rendering","tagline":"CMU 15-462/662 Assignment 5: Advanced Monte Carlo Rendering","body":"## Option F: Advanced Monte Carlo Rendering\r\n\r\n![Advanced rendering example]( http://15462.courses.cs.cmu.edu/fall2015content/misc/asst5_images/advancedrendering.png)\r\n\r\nFinally, you could extend the physically-based renderer you started to develop for your third assignment—as you experienced first-hand, the basic path tracing algorithm does not converge very quickly!  It also doesn't capture some important (and beautiful!) physical phenomena.  Here are several specific suggestions for directions you might pursue:\r\n\r\n* _Improve performance of BVH construction._  For large and/or dynamic scenes, the cost of building a bounding volume hierarchy is specific.  Consider, for instance, running a large, mesh-based physical simulation of water, which you then want to ray trace in order to get beautiful caustics.  Lots of geometry changing in unpredictable ways—and _millions_ of rays to properly resolve the appearance of the surface.  You could improve the performance of your renderer by implementing one of the the top modern parallel BVH build algorithms such as\r\n   * [Efficient BVH Construction via Approximate Agglomerative Clustering](http://graphics.cs.cmu.edu/projects/aac/)\r\n   * [Fast Parallel Construction of High-Quality Bounding Volume Hierarchies](https://research.nvidia.com/publication/fast-parallel-construction-high-quality-bounding-volume-hierarchies)\r\n* _Improve performance of ray tracing._  There are also plenty of opportunities to improve the performance of the ray tracing itself.  One possibility is to implement fast packet-based ray tracing a la the method described in, [\"Ray Tracing Deformable Scenes using Dynamic Bounding Volume Hierarchies\"](http://graphics.stanford.edu/~boulos/papers/togbvh.pdf).\r\n* _Implement an advanced global sampling algorithm._ A very different way to reduce the cost of rendering an image is to improve the sampling strategy.  In other words, since each ray can be very expensive to intersect with the scene, it makes sense to put some effort into finding paths that are likely to carry a lot of \"light.\"  The ultimate goal is to \"beat the clock,\" i.e., your fancy strategy should not only give better estimates of the integral as a function of number of rays cast, but it should really decrease the overall render time for a fixed target level of noise (i.e., an estimate of the variance of your estimator).  We discussed a number of these methods in our _Advanced Rendering and Sampling_ lecture; a few you might consider are given in the following list (many of these methods are excellently described in the [PBRT book](http://www.pbrt.org)):\r\n   * [bidirectional path tracing](https://en.wikipedia.org/wiki/Path_tracing#Bidirectional_path_tracing)\r\n   * [Photon mapping](https://en.wikipedia.org/wiki/Photon_mapping)\r\n   * [Metropolis light transport](https://graphics.stanford.edu/papers/metro/)—this method is quite advanced, though the [\"hypercube\" picture](http://sirkan.iit.bme.hu/~szirmay/paper50_electronic.pdf) we discussed in class can make it a bit easier to implement.\r\n* _Improved sampling patterns_. We also discussed a variety of strategies for picking more intelligent sampling patterns (stratified sampling, low-discrepancy, blue noise, etc.).  You could implement a variety of strategies and, like the previous item, compare the estimated variance of the estimator relative to the wall clock time used to render.\r\n* _Irradiance caching_.  A method that is extremely important in practice (i.e., almost all \"real\" renderers use it) but that we didn't have a chance to discuss in class is _irradiance caching_.  In a nutshell the idea is to say: if illumination is varying slowly, you sometimes get away with interpolating existing samples rather than generating new ones.  Exactly _how_ you generate these samples (and how you interpolate them) is critical to getting good results, and plenty has been written on the subject.  But even a basic irradiance caching strategy could greatly improve the utility of your renderer, in the sense that you can get far smoother images with far fewer samples.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}